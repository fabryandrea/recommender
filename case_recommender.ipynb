{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Movie Recommendations with Spark and the Surprise Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Company X has used production recommenders for many years now. The current recommender, called Mean of Means, relies on per-user and per-item rating means and incorporates the global mean for smoothing. Mean of Means provides a significant revenue stream so product managers are hesitant to touch it. The issue is that these systems have been around a long time. The task to explore new solutions. The main goals are to improve the Root Mean Square Error (RMSE) on the predictions, create a working recommender written in Spark, and use the surprise library to explore other models that could be prototyped for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Current Production Recommender: the Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I ran the current recommender used in production. It was provided in the Baselines.py file. I added slight updates to the code in order to cross-validate the results on five folds and print the standard deviation of the RMSE over the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Mean...\n",
      "Evaluating RMSE, MAE of algorithm GlobalMean on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1279  1.1183  1.1316  1.1217  1.1289  1.1257  0.0049  \n",
      "MAE (testset)     0.9453  0.9399  0.9521  0.9416  0.9448  0.9447  0.0042  \n",
      "Fit time          0.02    0.04    0.04    0.04    0.04    0.04    0.01    \n",
      "Test time         0.06    0.06    0.05    0.05    0.12    0.07    0.02    \n",
      "\n",
      "MeanOfMeans...\n",
      "Evaluating RMSE, MAE of algorithm MeanofMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0144  1.0228  1.0150  1.0156  1.0195  1.0175  0.0032  \n",
      "MAE (testset)     0.8353  0.8415  0.8336  0.8348  0.8423  0.8375  0.0036  \n",
      "Fit time          0.18    0.21    0.21    0.21    0.21    0.20    0.01    \n",
      "Test time         0.30    0.30    0.30    0.30    0.24    0.29    0.02    \n"
     ]
    }
   ],
   "source": [
    "import Baselines\n",
    "%run Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline recommender has a Root Mean Square Error of 1.0175, with a standard deviation of 0.0032. Just to make sure all changes in the RMSE are accounted for over all recommender models, I will use the coefficient of variation from now on. So our baseline is an RMSE of 1.0175 with a CV of 31.44%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Surprise Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise’s recommenders fall into 4 basic types: \n",
    "* baseline, \n",
    "* k-Nearest Neighbors (with pearson and cosine similarity distance metric options), \n",
    "* matrix factorization-based recommendation engines (SVD and NMF, plus an extension of SVD for implicit ratings), and\n",
    "* slope one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this guide for more detail on each: http://surprise.readthedocs.io/en/stable/basic_algorithms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load smaller built in Movielens dataset for evaluating\n",
    "from surprise import Dataset\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I have a baseline already (the \"Mean of Means\" algorithm currently in use and the RMSE level it produces), I started by running the baseline algorithm from surprise library, trying both Alternating Least Squares and Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9379  0.9471  0.9406  0.9379  0.9431  0.9413  0.0035  \n",
      "MAE (testset)     0.7433  0.7499  0.7436  0.7439  0.7469  0.7455  0.0026  \n",
      "Fit time          0.13    0.15    0.16    0.12    0.12    0.13    0.02    \n",
      "Test time         0.14    0.14    0.14    0.08    0.13    0.12    0.02    \n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0795  1.0738  1.0876  1.0804  1.0703  1.0783  0.0059  \n",
      "MAE (testset)     0.9026  0.8994  0.9092  0.9041  0.8927  0.9016  0.0055  \n",
      "Fit time          0.32    0.34    0.35    0.41    0.41    0.37    0.04    \n",
      "Test time         0.12    0.12    0.08    0.15    0.12    0.12    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (0.31844019889831543,\n",
       "  0.34000301361083984,\n",
       "  0.3462808132171631,\n",
       "  0.4146289825439453,\n",
       "  0.412550687789917),\n",
       " 'test_mae': array([0.90257548, 0.89936624, 0.90915863, 0.90410012, 0.89269288]),\n",
       " 'test_rmse': array([1.07946294, 1.07382762, 1.08760853, 1.08040708, 1.07028132]),\n",
       " 'test_time': (0.12273168563842773,\n",
       "  0.1241147518157959,\n",
       "  0.07518982887268066,\n",
       "  0.14624381065368652,\n",
       "  0.12252092361450195)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import BaselineOnly\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# try baseline with ALS\n",
    "# tuning bsl_options\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 5,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "base_als = BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "cross_validate(base_als, data, cv=5, verbose=True)\n",
    "\n",
    "# try baseline with SGD\n",
    "bsl_options = {'method': 'sgd',\n",
    "               'learning_rate': .00005,\n",
    "               }\n",
    "base_sgd = BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "cross_validate(base_sgd, data, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS did far better, with an RMSE of 94.06 (higher CV of 37.18%), achieving nearly a 7.5% improvement over the current recommender. That bodes well for building a production-ready recommender in Spark, since the Spark MLIb machine learning library only has one recommender option, which is ALS based. Next, I will take a look at Slope One, another easy baseline algorithm from the library (this one has no hyperparameters whatsoever). For more on this algorithm, see this Wikipedia article: https://en.wikipedia.org/wiki/Slope_One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Slope One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SlopeOne on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9455  0.9416  0.9419  0.9519  0.9437  0.9449  0.0038  \n",
      "MAE (testset)     0.7438  0.7386  0.7394  0.7486  0.7445  0.7430  0.0037  \n",
      "Fit time          0.68    0.67    0.70    0.67    0.63    0.67    0.02    \n",
      "Test time         2.20    2.03    1.97    1.85    1.90    1.99    0.12    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (0.6811401844024658,\n",
       "  0.6733529567718506,\n",
       "  0.7013638019561768,\n",
       "  0.6749172210693359,\n",
       "  0.6329629421234131),\n",
       " 'test_mae': array([0.74382186, 0.73862904, 0.73935682, 0.7486076 , 0.74451141]),\n",
       " 'test_rmse': array([0.94547797, 0.94163869, 0.94186666, 0.95191744, 0.94370444]),\n",
       " 'test_time': (2.198395013809204,\n",
       "  2.029664993286133,\n",
       "  1.9730260372161865,\n",
       "  1.8469529151916504,\n",
       "  1.8984408378601074)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No params!!!\n",
    "from surprise import SlopeOne\n",
    "\n",
    "cross_validate(SlopeOne(), data, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even Slope One does better than the existing algorithm used in production. The average RMSE is 0.9449 with a CV of 40.22%. That means both baseline algorithms do better predictions than the existing recommender on average but the quality of their predictions have a bit wider range than the existing ones. They still both do much better than the existing system. Next, I will try co-clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Co-Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-clustering is a dynamic real-time collaborative filtering engine that simultaneously clusters users and items. Here, I used the default settings of 3 user clusters, 3 item clusters, and 20 iterations of the optimization loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm CoClustering on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9611  0.9700  0.9650  0.9622  0.9644  0.9645  0.0031  \n",
      "MAE (testset)     0.7524  0.7575  0.7543  0.7561  0.7549  0.7550  0.0017  \n",
      "Fit time          1.48    1.47    1.47    1.48    1.49    1.48    0.01    \n",
      "Test time         0.08    0.19    0.08    0.19    0.08    0.12    0.05    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (1.481929063796997,\n",
       "  1.4680471420288086,\n",
       "  1.4674088954925537,\n",
       "  1.4812119007110596,\n",
       "  1.4904828071594238),\n",
       " 'test_mae': array([0.75236666, 0.75746018, 0.75427586, 0.7560816 , 0.7548954 ]),\n",
       " 'test_rmse': array([0.96107374, 0.97000246, 0.96495001, 0.96216753, 0.96437651]),\n",
       " 'test_time': (0.08111095428466797,\n",
       "  0.19227886199951172,\n",
       "  0.08017110824584961,\n",
       "  0.1897718906402588,\n",
       "  0.08066105842590332)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import CoClustering\n",
    "\n",
    "cross_validate(CoClustering(), data, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE was lower than the baseline, but not particularly impressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN is a machine learning algorithm that finds clusters of similar users based on common item ratings, and makes predictions using the average rating of top k number nearest neighbors. In surprise, there are a number of hyperparameters that can be tuned besides k (the number of nearest neighbors): whether I want to use average rating, z-score rating, baseline rating to group the clusters and whether I want to use cosine similarity or pearson distance metrics for measuring \"nearness.\" For a step-by-step tutorial on kNN not using surprise library, see: https://towardsdatascience.com/how-did-we-build-book-recommender-systems-in-an-hour-part-2-k-nearest-neighbors-and-matrix-c04b3c2ef55c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9361  0.9417  0.9395  0.9506  0.9409  0.9418  0.0048  \n",
      "MAE (testset)     0.7374  0.7413  0.7364  0.7439  0.7430  0.7404  0.0030  \n",
      "Fit time          1.39    1.42    1.51    1.29    1.39    1.40    0.07    \n",
      "Test time         3.22    3.18    3.21    3.20    3.15    3.19    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (1.3855597972869873,\n",
       "  1.4217870235443115,\n",
       "  1.5068080425262451,\n",
       "  1.2944920063018799,\n",
       "  1.3911669254302979),\n",
       " 'test_mae': array([0.73741888, 0.74128558, 0.73639748, 0.74385914, 0.74295172]),\n",
       " 'test_rmse': array([0.9360551 , 0.94170234, 0.93951627, 0.950621  , 0.94087471]),\n",
       " 'test_time': (3.2197039127349854,\n",
       "  3.1824898719787598,\n",
       "  3.2069740295410156,\n",
       "  3.1991658210754395,\n",
       "  3.1527531147003174)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN has many versions, they take different similarity measures under sim_options param\n",
    "# levers to tune similarity measures: cosine, Pearson\n",
    "# other params: k, min_k\n",
    "# knns.KNNWithMeans (mean rating of users)\n",
    "from surprise import KNNWithMeans\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False\n",
    "}\n",
    "\n",
    "knn_m = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "cross_validate(knn_m, data, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9458  0.9383  0.9460  0.9410  0.9369  0.9416  0.0038  \n",
      "MAE (testset)     0.7424  0.7413  0.7461  0.7409  0.7392  0.7420  0.0023  \n",
      "Fit time          1.63    1.62    1.45    1.49    1.59    1.55    0.07    \n",
      "Test time         3.56    3.34    3.30    3.44    3.55    3.44    0.11    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (1.6262061595916748,\n",
       "  1.6176371574401855,\n",
       "  1.45363187789917,\n",
       "  1.4893670082092285,\n",
       "  1.5877439975738525),\n",
       " 'test_mae': array([0.74241672, 0.7412705 , 0.74611266, 0.74090039, 0.73923614]),\n",
       " 'test_rmse': array([0.94578761, 0.9382898 , 0.94599386, 0.94095897, 0.93687012]),\n",
       " 'test_time': (3.5579068660736084,\n",
       "  3.3396248817443848,\n",
       "  3.299196720123291,\n",
       "  3.4366979598999023,\n",
       "  3.554590940475464)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knns.KNNBaseline (baseline rating)\n",
    "# has additional bsl_options\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'pearson',\n",
    "    'user_based': False\n",
    "}\n",
    "\n",
    "knn_b = KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "cross_validate(knn_b, data, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran a variety of versions of kNN (only kept the code for two of the highest performing ones): RMSE of 0.9418 and CV of 50.97% for using average ratings vs. RMSE of 0.9416 and a CV of 40.36% for using baseline ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last type of recommender systems in surprise relies on matrix factorization. Here's a breakdown of the two words in the name of this approach:\n",
    "* Factor: The matrix factorization approach makes recommendations by finding latent factors that are not necessarily apparent in the data. (For example, when I log into Netflix, one of the latent factors in my recommendation feed is \"international criminal investigation TV dramas.\" A label like that wouldn't necessarily be found on imdb.com, but it is a strongh enough feature to describe a number of items offered by Netflix.) \n",
    "* Matrix: Using linear algrebra, the user-item matrix can be decomposed into several parts: a user-feature matrix and a movie-feature matrix. Those two parts then can be recombined, giving us predicted “ratings” for movies not yet seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For good basic introductions on matrix factorization, see:\n",
    "* https://blog.insightdatascience.com/explicit-matrix-factorization-als-sgd-and-all-that-jazz-b00e4d9b21ea\n",
    "* https://www.datacamp.com/community/tutorials/matrix-factorization-names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9344  0.9287  0.9357  0.9397  0.9337  0.9344  0.0036  \n",
      "MAE (testset)     0.7385  0.7303  0.7363  0.7409  0.7352  0.7363  0.0036  \n",
      "Fit time          4.15    4.18    4.19    4.23    4.31    4.21    0.06    \n",
      "Test time         0.12    0.18    0.18    0.12    0.19    0.16    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (4.148401975631714,\n",
       "  4.179248094558716,\n",
       "  4.18828010559082,\n",
       "  4.23301100730896,\n",
       "  4.311578750610352),\n",
       " 'test_mae': array([0.73852984, 0.73028014, 0.73633033, 0.74090837, 0.73520329]),\n",
       " 'test_rmse': array([0.93442533, 0.92868259, 0.93570543, 0.93972205, 0.9336977 ]),\n",
       " 'test_time': (0.11529302597045898,\n",
       "  0.18133306503295898,\n",
       "  0.18240094184875488,\n",
       "  0.11872696876525879,\n",
       "  0.19011807441711426)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "svd = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(svd, data, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9620  0.9591  0.9664  0.9608  0.9696  0.9636  0.0039  \n",
      "MAE (testset)     0.7564  0.7519  0.7605  0.7561  0.7641  0.7578  0.0042  \n",
      "Fit time          4.41    4.53    4.48    4.51    4.64    4.52    0.07    \n",
      "Test time         0.20    0.21    0.09    0.24    0.10    0.17    0.06    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (4.412101984024048,\n",
       "  4.534706115722656,\n",
       "  4.484484910964966,\n",
       "  4.512546062469482,\n",
       "  4.6404478549957275),\n",
       " 'test_mae': array([0.75643213, 0.75191407, 0.76046604, 0.7560633 , 0.76410932]),\n",
       " 'test_rmse': array([0.96203534, 0.95912811, 0.96638438, 0.96077173, 0.96964493]),\n",
       " 'test_time': (0.20378589630126953,\n",
       "  0.21161890029907227,\n",
       "  0.09108877182006836,\n",
       "  0.24230217933654785,\n",
       "  0.10178089141845703)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NMF\n",
    "from surprise import NMF\n",
    "nmf = NMF()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(nmf, data, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular Vector Decomposition (SVD) did much better than Negative Matrix Factorization (NMF): RMSE of 0.9344 with a CV of 38.53% for SVD vs. RMSE of 0.9636 and CV of 40.47% for NMF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Recommender in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate a spark session\n",
    "import pyspark as ps\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName(\"df lecture\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data: Ratings DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS only requires an input dataset of existing ratings between user-item pairs, with three columns: a user ID column, an item ID column (e.g., a movie), and a rating column. So I am only reading in the ratings part of the MovieLens dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|     31|   2.5|1260759144|\n",
      "|     1|   1029|   3.0|1260759179|\n",
      "|     1|   1061|   3.0|1260759182|\n",
      "|     1|   1129|   2.0|1260759185|\n",
      "|     1|   1172|   4.0|1260759205|\n",
      "|     1|   1263|   2.0|1260759151|\n",
      "|     1|   1287|   2.0|1260759187|\n",
      "|     1|   1293|   2.0|1260759148|\n",
      "|     1|   1339|   3.5|1260759125|\n",
      "|     1|   1343|   2.0|1260759131|\n",
      "|     1|   1371|   2.5|1260759135|\n",
      "|     1|   1405|   1.0|1260759203|\n",
      "|     1|   1953|   4.0|1260759191|\n",
      "|     1|   2105|   4.0|1260759139|\n",
      "|     1|   2150|   3.0|1260759194|\n",
      "|     1|   2193|   2.0|1260759198|\n",
      "|     1|   2294|   2.0|1260759108|\n",
      "|     1|   2455|   2.5|1260759113|\n",
      "|     1|   2968|   1.0|1260759200|\n",
      "|     1|   3671|   3.0|1260759117|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the many data types\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# create a schema of your own\n",
    "customSchema = StructType([\n",
    "   StructField('userId',IntegerType(),True),\n",
    "   StructField('movieId',IntegerType(),True),\n",
    "   StructField('rating',FloatType(),True),\n",
    "   StructField('timestamp',StringType(),True)\n",
    "])\n",
    "\n",
    "# use that schema in reading in df\n",
    "ratings_df = spark\\\n",
    "                .read\\\n",
    "                .schema(customSchema)\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv('data/movies/ratings.csv')\n",
    "\n",
    "\n",
    "# show the result\n",
    "ratings_df.show()\n",
    "\n",
    "# print the schema\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Ratings using Spark ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick overview of collaborative filtering in Spark ML, visit: https://spark.apache.org/docs/preview/ml-collaborative-filtering.html#examples (Also, the newly published Spark: The Definitive Guide is extremely helpful: http://shop.oreilly.com/product/0636920034957.do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.6254246953148832\n"
     ]
    }
   ],
   "source": [
    "# ALS with GridSearch\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "# we already have a df called ratings_df from above\n",
    "(training, test) = ratings_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# always create a new instance of a model before creating a pipeline\n",
    "# remember to set the coldStartStrategy back to 'NaN' for production\n",
    "#rForm = RFormula()\n",
    "als2 = ALS()\\\n",
    "            .setColdStartStrategy('drop')\\\n",
    "            .setUserCol(\"userId\")\\\n",
    "            .setItemCol(\"movieId\")\\\n",
    "            .setRatingCol(\"rating\")\n",
    "\n",
    "# add stages to pipeline\n",
    "stages = [als2]\n",
    "pipeline = Pipeline().setStages(stages)\n",
    "\n",
    "# parameter tuning\n",
    "params = ParamGridBuilder()\\\n",
    "        .addGrid(als2.rank, [10, 20, 40, 80])\\\n",
    "        .addGrid(als2.nonnegative, [True, False])\\\n",
    "        .addGrid(als2.regParam, [0.01, 0.02, 0.05, 0.08, 0.1, 0.15, 0.2])\\\n",
    "        .build()\n",
    "\n",
    "# specify evaluation process   \n",
    "evaluator = RegressionEvaluator()\\\n",
    "    .setMetricName(\"rmse\")\\\n",
    "    .setPredictionCol(\"prediction\")\\\n",
    "    .setLabelCol(\"rating\")\n",
    "\n",
    "# using crossvalidator for parameter search\n",
    "cv = CrossValidator()\\\n",
    "        .setEstimator(pipeline)\\\n",
    "        .setEvaluator(evaluator)\\\n",
    "        .setEstimatorParamMaps(params)\\\n",
    "        .setNumFolds(5)\n",
    "        \n",
    "ALSmodelGS = cv.fit(training)\n",
    "\n",
    "out = ALSmodelGS.transform(training)\\\n",
    "                .select(\"prediction\", \"rating\").rdd\\\n",
    "                .map(lambda x: (float(x[0]), float(x[1])))\n",
    "metrics = RegressionMetrics(out)\n",
    "\n",
    "print(\"Root-mean-square error = \" + str(metrics.rootMeanSquaredError))\n",
    "\n",
    "# once trained, we can persist it to desk and use it on other data\n",
    "# remember to set back coldStartStrategy to NaN\n",
    "# ALSmodelGS.write.overwrite().save(\"prediction_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running GridSearch, Spark's recommender reduced the RMSE to 0.6254! This solution clearly outperforms the existing Mean of Means and should be considered as a replacememnt engine for production."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
